{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8528d4c",
   "metadata": {},
   "source": [
    "# Week 3 | Assignment 2\n",
    "## Assignment 2: Personalized Course Recommendation Engine\n",
    "### 1. Background & Context\n",
    "Online learning platforms host thousands of courses across domains—learners often feel overwhelmed by choices. A personalized recommender that understands both course content and individual learner profiles can boost engagement and completion rates by suggesting the most relevant next steps.\n",
    "\n",
    "### 2. Problem Statement\n",
    "“Design and implement a Course Recommendation Engine that—given a user query (completed courses + a short interests blurb)—returns the top-5 most relevant courses from a catalog of course  offerings, using embedding models and a vector database for semantic matching.”\n",
    "\n",
    "### 3. Objectives & Learning Outcomes\n",
    "- Embeddings & Semantic Search: Convert course descriptions into high-dimensional vectors.\n",
    "- Vector Database: Index and query vectors for fast similarity retrieval.\n",
    "- Recommendation Logic: Rank courses by cosine similarity to the user query vector.\n",
    "- Basic UI/CLI (optional): Demonstrate the engine end-to-end with sample queries.\n",
    "\n",
    "### 4. Technical Requirements\n",
    "Data Ingestion & Indexing: Read the course catalog (title + description), compute embeddings, and upsert into a vector DB.\n",
    "Recommendation Logic & API:\n",
    "\n",
    "```python\n",
    "def recommend_courses(profile: str, completed_ids: List[str]) ->\n",
    "List[Tuple[str, float]]:\n",
    "\"\"\"\n",
    "Returns a list of (course_id, similarity_score) for the top-5\n",
    "recommendations.\n",
    "\"\"\"\n",
    "```\n",
    "### 5. Deliverables\n",
    "- Code: Jupyter notebook file in PDF format OR .py files in zip (keep requirements .txt if needed)\n",
    "- Evaluation Report: Jupyter Notebook should include test results for each of 5 test profiles, list recommendations and comment on relevance.\n",
    "\n",
    "### 6. Dataset\n",
    "\n",
    "Dataset file: assignment2data.csv\n",
    "\n",
    "https://raw.githubusercontent.com/Bluedata-Consulting/GAAPB01-training-code-base/refs/heads/main/Assignments/assignment2dataset.csv\n",
    "\n",
    "### 7. Sample Input Queries\n",
    "- “I’ve completed the ‘Python Programming for Data Science’ course and enjoy data visualization. What should I take next?”\n",
    "- “I know Azure basics and want to manage containers and build CI/CD pipelines. Recommend courses.”\n",
    "- “My background is in ML fundamentals; I’d like to specialize in neural networks and production workflows.”\n",
    "- “I want to learn to build and deploy microservices with Kubernetes—what courses fit best?”\n",
    "- “I’m interested in blockchain and smart contracts but have no prior experience. Which courses do you suggest?”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b283edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install langchain-text-splitters ragas --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7353c9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zadmin/Desktop/GAAI-B4-Azure/genai/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Optional, Tuple, Dict\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from ragas import evaluate\n",
    "from ragas import evaluate, SingleTurnSample, EvaluationDataset\n",
    "from ragas.metrics import AnswerRelevancy, Faithfulness, ContextPrecision\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import json\n",
    "\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9169d5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5feb0fc",
   "metadata": {},
   "source": [
    "### Initializing LLM & Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da7c59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureChatOpenAI(\n",
    "    deployment_name=os.environ['AZURE_OPENAI_DEPLOYMENT'],  # Your deployment name\n",
    "        model_name=\"gpt-4o\",\n",
    "        temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e79f4f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick LLM Invokation test to verify model deployment\n",
    "\n",
    "client.invoke('What is the capital of France?').content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27cf8d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_model = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af914dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0035696455743163824, 0.008301939815282822, -0.014215736649930477, -0.004543756600469351, -0.01546008512377739, 0.01862751692533493, -0.02047518640756607, -0.010218738578259945, -0.012883404269814491, -0.028129812330007553]\n"
     ]
    }
   ],
   "source": [
    "# Quick Embedding model test to verify model deployment\n",
    "\n",
    "print(embedding_model.embed_query(\"The quick brown fox jumps over the lazy dog\")[:10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97817ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Quick Similarity Test\n",
    "\n",
    "print(\"Cosine Similarity:\",cosine_similarity(\n",
    "    np.array(embedding_model.embed_query(\"It's a lovely day outside\")).reshape(-1, 1),\n",
    "    np.array(embedding_model.embed_query(\"The weather today is beautiful\")).reshape(-1,1)\n",
    ")[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4133443",
   "metadata": {},
   "source": [
    "### Reading Given Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "422b2f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C001</td>\n",
       "      <td>Foundations of Machine Learning</td>\n",
       "      <td>Understand foundational machine learning algor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C002</td>\n",
       "      <td>Deep Learning with TensorFlow and Keras</td>\n",
       "      <td>Explore neural network architectures using Ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C003</td>\n",
       "      <td>Natural Language Processing Fundamentals</td>\n",
       "      <td>Dive into NLP techniques for processing and un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C004</td>\n",
       "      <td>Computer Vision and Image Processing</td>\n",
       "      <td>Learn the principles of computer vision and im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C005</td>\n",
       "      <td>Reinforcement Learning Basics</td>\n",
       "      <td>Get introduced to reinforcement learning parad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C006</td>\n",
       "      <td>Data Engineering on AWS</td>\n",
       "      <td>Build scalable data pipelines using AWS servic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C007</td>\n",
       "      <td>Cloud Computing with Azure</td>\n",
       "      <td>Master Microsoft Azure’s core services: virtua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C008</td>\n",
       "      <td>DevOps Practices and CI/CD</td>\n",
       "      <td>Adopt DevOps methodologies to accelerate softw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C009</td>\n",
       "      <td>Containerization with Docker and Kubernetes</td>\n",
       "      <td>Learn container fundamentals with Docker: imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C010</td>\n",
       "      <td>APIs and Microservices Architecture</td>\n",
       "      <td>Design and implement RESTful and GraphQL APIs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C011</td>\n",
       "      <td>Big Data Analytics with Spark</td>\n",
       "      <td>Process and analyze large datasets using Apach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C012</td>\n",
       "      <td>SQL for Data Analysis</td>\n",
       "      <td>Master SQL querying for data analysis and repo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C013</td>\n",
       "      <td>NoSQL Databases and MongoDB</td>\n",
       "      <td>Explore NoSQL paradigms: key-value, document, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C014</td>\n",
       "      <td>Data Visualization with Tableau</td>\n",
       "      <td>Transform raw data into compelling visual stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C015</td>\n",
       "      <td>Business Intelligence with Power BI</td>\n",
       "      <td>Leverage Microsoft Power BI to build dynamic b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C016</td>\n",
       "      <td>Python Programming for Data Science</td>\n",
       "      <td>Learn Python fundamentals for data science: va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C017</td>\n",
       "      <td>R Programming and Statistical Analysis</td>\n",
       "      <td>Get introduced to R for statistical computing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C018</td>\n",
       "      <td>Product Management Essentials</td>\n",
       "      <td>Understand the product lifecycle from ideation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C019</td>\n",
       "      <td>Agile and Scrum Mastery</td>\n",
       "      <td>Adopt Agile frameworks to enhance team product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C020</td>\n",
       "      <td>User Experience (UX) Design Principles</td>\n",
       "      <td>Learn UX design fundamentals: user research, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>C021</td>\n",
       "      <td>Cybersecurity Fundamentals</td>\n",
       "      <td>Get introduced to cybersecurity principles: th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>C022</td>\n",
       "      <td>Internet of Things (IoT) Development</td>\n",
       "      <td>Explore IoT architecture, sensors, and edge co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>C023</td>\n",
       "      <td>Blockchain Technology and Smart Contracts</td>\n",
       "      <td>Understand blockchain fundamentals: cryptograp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>C024</td>\n",
       "      <td>Augmented and Virtual Reality Development</td>\n",
       "      <td>Dive into AR/VR concepts, device ecosystems, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>C025</td>\n",
       "      <td>MLOps: Productionizing Machine Learning</td>\n",
       "      <td>Master the practices needed to deploy and main...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   course_id                                        title  \\\n",
       "0       C001              Foundations of Machine Learning   \n",
       "1       C002      Deep Learning with TensorFlow and Keras   \n",
       "2       C003     Natural Language Processing Fundamentals   \n",
       "3       C004         Computer Vision and Image Processing   \n",
       "4       C005                Reinforcement Learning Basics   \n",
       "5       C006                      Data Engineering on AWS   \n",
       "6       C007                   Cloud Computing with Azure   \n",
       "7       C008                   DevOps Practices and CI/CD   \n",
       "8       C009  Containerization with Docker and Kubernetes   \n",
       "9       C010          APIs and Microservices Architecture   \n",
       "10      C011                Big Data Analytics with Spark   \n",
       "11      C012                        SQL for Data Analysis   \n",
       "12      C013                  NoSQL Databases and MongoDB   \n",
       "13      C014              Data Visualization with Tableau   \n",
       "14      C015          Business Intelligence with Power BI   \n",
       "15      C016          Python Programming for Data Science   \n",
       "16      C017       R Programming and Statistical Analysis   \n",
       "17      C018                Product Management Essentials   \n",
       "18      C019                      Agile and Scrum Mastery   \n",
       "19      C020       User Experience (UX) Design Principles   \n",
       "20      C021                   Cybersecurity Fundamentals   \n",
       "21      C022         Internet of Things (IoT) Development   \n",
       "22      C023    Blockchain Technology and Smart Contracts   \n",
       "23      C024    Augmented and Virtual Reality Development   \n",
       "24      C025      MLOps: Productionizing Machine Learning   \n",
       "\n",
       "                                          description  \n",
       "0   Understand foundational machine learning algor...  \n",
       "1   Explore neural network architectures using Ten...  \n",
       "2   Dive into NLP techniques for processing and un...  \n",
       "3   Learn the principles of computer vision and im...  \n",
       "4   Get introduced to reinforcement learning parad...  \n",
       "5   Build scalable data pipelines using AWS servic...  \n",
       "6   Master Microsoft Azure’s core services: virtua...  \n",
       "7   Adopt DevOps methodologies to accelerate softw...  \n",
       "8   Learn container fundamentals with Docker: imag...  \n",
       "9   Design and implement RESTful and GraphQL APIs ...  \n",
       "10  Process and analyze large datasets using Apach...  \n",
       "11  Master SQL querying for data analysis and repo...  \n",
       "12  Explore NoSQL paradigms: key-value, document, ...  \n",
       "13  Transform raw data into compelling visual stor...  \n",
       "14  Leverage Microsoft Power BI to build dynamic b...  \n",
       "15  Learn Python fundamentals for data science: va...  \n",
       "16  Get introduced to R for statistical computing ...  \n",
       "17  Understand the product lifecycle from ideation...  \n",
       "18  Adopt Agile frameworks to enhance team product...  \n",
       "19  Learn UX design fundamentals: user research, p...  \n",
       "20  Get introduced to cybersecurity principles: th...  \n",
       "21  Explore IoT architecture, sensors, and edge co...  \n",
       "22  Understand blockchain fundamentals: cryptograp...  \n",
       "23  Dive into AR/VR concepts, device ecosystems, a...  \n",
       "24  Master the practices needed to deploy and main...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/Bluedata-Consulting/GAAPB01-training-code-base/refs/heads/main/Assignments/assignment2dataset.csv\"\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de9bce4",
   "metadata": {},
   "source": [
    "### Creating Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffdd792f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vector store with 25 courses...\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for _, row in df.iterrows():\n",
    "    # Combine title and description for richer semantic representation\n",
    "    content = f\"Title: {row['title']}\\nDescription: {row['description']}\"\n",
    "    doc = Document(\n",
    "        page_content=content,\n",
    "        metadata={\n",
    "            'course_id': row['course_id'],\n",
    "            'title': row['title'],\n",
    "            'description': row['description']\n",
    "        }\n",
    "    )\n",
    "    documents.append(doc)\n",
    "\n",
    "print(f\"Creating vector store with {len(documents)} courses...\")\n",
    "vector_store = FAISS.from_documents(documents, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfbaf906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x726cca8952b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e107ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"\"\"I’ve completed the ‘Python Programming for Data Science’ course and enjoy data visualization. What should I take next?\"\"\",\n",
    "    \"\"\"I know Azure basics and want to manage containers and build CI/CD pipelines. Recommend courses.\"\"\",\n",
    "    \"\"\"“My background is in ML fundamentals; I’d like to specialize in neural networks and production workflows.\"\"\",\n",
    "    \"\"\"I want to learn to build and deploy microservices with Kubernetes—what courses fit best?\"\"\",\n",
    "    \"\"\"I’m interested in blockchain and smart contracts but have no prior experience. Which courses do you suggest?\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32d9fc4",
   "metadata": {},
   "source": [
    "### Parsing User Query to understand their profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a8250e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_user_query(query: str, df: pd.DataFrame, vector_store: FAISS, llm: AzureChatOpenAI) -> Dict:\n",
    "    \"\"\"\n",
    "    Use LLM + Vector DB to extract completed courses and user interests from natural language query.\n",
    "    Uses semantic search to identify courses mentioned in the query.\n",
    "    \"\"\"\n",
    "    # Step 1: Use LLM to identify course mentions in the query\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a course recommendation assistant. Analyze the user's query and extract:\n",
    "1. Course mentions: Extract any course names or topics the user mentions as \"completed\" or \"taken\"\n",
    "2. User interests: What does the user want to learn next?\n",
    "\n",
    "Return your response in JSON format:\n",
    "{{\n",
    "    \"completed_course_mentions\": [\"Python Programming for Data Science\", \"Azure basics\"],\n",
    "    \"user_interests\": \"Brief summary of what user wants to learn next\",\n",
    "    \"search_query\": \"Optimized search query for finding new relevant courses\"\n",
    "}}\n",
    "\n",
    "If no courses are mentioned as completed, return empty list.\n",
    "The search_query should focus on what the user wants to learn NEXT, not what they've completed.\"\"\"),\n",
    "        (\"user\", \"{query}\")\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"query\": query})\n",
    "    \n",
    "    # Parse JSON response\n",
    "    try:\n",
    "        llm_parsed = json.loads(response.content)\n",
    "    except:\n",
    "        llm_parsed = {\n",
    "            \"completed_course_mentions\": [],\n",
    "            \"user_interests\": query,\n",
    "            \"search_query\": query\n",
    "        }\n",
    "    \n",
    "    # Step 2: Use vector DB to match mentioned courses to actual course IDs\n",
    "    completed_course_ids = []\n",
    "    completed_course_names = []\n",
    "    \n",
    "    for mention in llm_parsed.get(\"completed_course_mentions\", []):\n",
    "        # Use semantic search to find matching courses\n",
    "        matches = vector_store.similarity_search(mention, k=1)\n",
    "        if matches:\n",
    "            matched_course_id = matches[0].metadata['course_id']\n",
    "            matched_course_name = matches[0].metadata['title']\n",
    "            completed_course_ids.append(matched_course_id)\n",
    "            completed_course_names.append(matched_course_name)\n",
    "    \n",
    "    return {\n",
    "        \"completed_course_ids\": completed_course_ids,\n",
    "        \"completed_course_names\": completed_course_names,\n",
    "        \"user_interests\": llm_parsed.get(\"user_interests\", query),\n",
    "        \"search_query\": llm_parsed.get(\"search_query\", query)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c03dfc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completed_course_ids': ['C016'],\n",
       " 'completed_course_names': ['Python Programming for Data Science'],\n",
       " 'user_interests': 'The user wants to learn more about data visualization.',\n",
       " 'search_query': 'Data visualization courses for Python'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_user_query(\n",
    "    query = test_queries[0], \n",
    "    df = df, \n",
    "    vector_store=vector_store, \n",
    "    llm = client\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932eb96d",
   "metadata": {},
   "source": [
    "### Retriever Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5b3d9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_courses(\n",
    "    profile: str,\n",
    "    # completed_ids: List[str],\n",
    "    vector_store: FAISS,\n",
    "    df: pd.DataFrame,\n",
    "    llm: AzureChatOpenAI,\n",
    "    top_k: int = 5\n",
    ") -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Returns top-K course recommendations using LLM for query understanding\n",
    "    and vector search for semantic matching.\n",
    "    \n",
    "    Args:\n",
    "        profile: User's natural language query\n",
    "        completed_ids: Pre-extracted completed course IDs (for API usage)\n",
    "        vector_store: FAISS vector database\n",
    "        df: Course catalog DataFrame\n",
    "        llm: Language model for query parsing\n",
    "        top_k: Number of recommendations to return\n",
    "    \n",
    "    Returns:\n",
    "        List of (course_id, similarity_score) tuples\n",
    "    \"\"\"\n",
    "    # Use LLM to parse query and understand user intent\n",
    "    parsed = parse_user_query(profile, df, vector_store, llm)\n",
    "    \n",
    "    print(f\"LLM Analysis:\")\n",
    "    print(f\"  Completed Courses: {parsed['completed_course_names']}\")\n",
    "    print(f\"  Course IDs: {parsed['completed_course_ids']}\")\n",
    "    print(f\"  User Interests: {parsed['user_interests']}\")\n",
    "    print(f\"  Search Query: {parsed['search_query']}\\n\")\n",
    "    \n",
    "    # Merge completed courses from parsing and explicit input\n",
    "    all_completed = list(set(parsed['completed_course_ids']))\n",
    "    \n",
    "    # Use optimized search query from LLM\n",
    "    search_query = parsed['search_query']\n",
    "    \n",
    "    # Retrieve more candidates to account for filtering\n",
    "    retrieval_k = top_k + len(all_completed) + 10\n",
    "    \n",
    "    # Perform semantic search\n",
    "    results = vector_store.similarity_search_with_score(search_query, k=retrieval_k)\n",
    "    \n",
    "    # Filter and rank\n",
    "    recommendations = []\n",
    "    for doc, score in results:\n",
    "        course_id = doc.metadata['course_id'] \n",
    "        description = doc.metadata['description']\n",
    "        \n",
    "        if course_id in all_completed:\n",
    "            continue\n",
    "        \n",
    "        # Convert FAISS L2 distance to similarity score\n",
    "        similarity_score = 1 / (1 + score)\n",
    "        recommendations.append({\n",
    "            \"course_id\":course_id,\n",
    "            \"course_title\":doc.metadata['title'],\n",
    "            \"course_description\":description,\n",
    "            \"similarity_score\":round(similarity_score.item(), 3)\n",
    "        })\n",
    "        \n",
    "        if len(recommendations) >= top_k:\n",
    "            break\n",
    "    \n",
    "    return recommendations, parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69067b6d",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d306e9ca",
   "metadata": {},
   "source": [
    "The output contains top_k=5 recommendations of courses for a user query, based on cosine similarity scores betweent the query (incl. completed courses - already completed ones, if any) & retrieved courses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddbee244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Analysis:\n",
      "  Completed Courses: ['Python Programming for Data Science']\n",
      "  Course IDs: ['C016']\n",
      "  User Interests: The user wants to learn more about data visualization.\n",
      "  Search Query: Data visualization courses for Python\n",
      "\n",
      "[{'course_id': 'C011', 'course_title': 'Big Data Analytics with Spark', 'course_description': 'Process and analyze large datasets using Apache Spark and PySpark. The course covers RDDs, DataFrames, Spark SQL, and MLlib for machine learning at scale. You’ll learn cluster deployment on YARN or Kubernetes, performance tuning, and structured streaming for real-time analytics. Hands-on projects include building ETL pipelines and interactive dashboards, unlocking insights from big data.', 'similarity_score': 0.747}, {'course_id': 'C014', 'course_title': 'Data Visualization with Tableau', 'course_description': 'Transform raw data into compelling visual stories using Tableau. Learn to connect to diverse data sources, create interactive dashboards, and apply best practices in chart selection. Topics include calculated fields, parameters, LOD expressions, and storytelling features. Through real-world case studies, you’ll design user-driven analytics that reveal trends and drive data-informed decision making.', 'similarity_score': 0.737}, {'course_id': 'C004', 'course_title': 'Computer Vision and Image Processing', 'course_description': 'Learn the principles of computer vision and image processing. Topics include filtering, edge detection, feature extraction, image segmentation, object detection, and image classification using CNNs. Hands-on labs in Python leverage OpenCV, scikit-image, and TensorFlow. By project’s end, you will build a pipeline to analyze and classify images, detect objects, and perform real-time video processing.', 'similarity_score': 0.719}, {'course_id': 'C012', 'course_title': 'SQL for Data Analysis', 'course_description': 'Master SQL querying for data analysis and reporting. Topics include SELECT statements, JOINs, subqueries, window functions, CTEs, and aggregate functions. Practice on PostgreSQL or MySQL to manipulate data, generate summary statistics, and create analytical views. Labs cover query optimization, indexing strategies, and writing complex reports, empowering you to derive actionable insights from relational data.', 'similarity_score': 0.715}, {'course_id': 'C017', 'course_title': 'R Programming and Statistical Analysis', 'course_description': 'Get introduced to R for statistical computing and graphics. Topics include data structures, control flow, and functional programming. Use tidyverse libraries—dplyr, ggplot2, tidyr—for data manipulation and visualization. Explore hypothesis testing, regression analysis, and ANOVA. Through labs, apply statistical methods to real-world datasets and communicate results with reproducible R Markdown reports.', 'similarity_score': 0.713}]\n"
     ]
    }
   ],
   "source": [
    "recommendations, parsed_obj = recommend_courses(\n",
    "    profile=test_queries[0],\n",
    "    vector_store=vector_store,\n",
    "    df=df,\n",
    "    llm=client\n",
    ")\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d050bb15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
